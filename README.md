# ğŸŒ Web Content Scraper

Application Next.js moderne pour rÃ©cupÃ©rer et analyser le contenu HTML, CSS et JavaScript de n'importe quelle page web accessible publiquement.

![Next.js](https://img.shields.io/badge/Next.js-13+-black?style=flat-square&logo=next.js)
![React](https://img.shields.io/badge/React-18+-61dafb?style=flat-square&logo=react)
![Tailwind CSS](https://img.shields.io/badge/Tailwind-3+-38bdf8?style=flat-square&logo=tailwind-css)

## âœ¨ FonctionnalitÃ©s

- ğŸ¨ **Interface moderne** avec Tailwind CSS et dÃ©gradÃ©s Ã©lÃ©gants
- ğŸ“„ **Extraction sÃ©parÃ©e** du HTML, CSS et JavaScript
- ğŸ”„ **SÃ©paration intelligente** - Le HTML est nettoyÃ© sans balises `<style>` et `<script>`
- ğŸ“‹ **Copie en un clic** - Copiez le code dans le presse-papier
- ğŸ’¾ **TÃ©lÃ©chargement** - TÃ©lÃ©chargez chaque type de fichier sÃ©parÃ©ment
- ğŸ• **Historique** - Menu dÃ©roulant avec les 10 derniÃ¨res URLs analysÃ©es
- âš¡ **Chargement instantanÃ©** - Rechargez une URL depuis l'historique sans nouvelle requÃªte
- ğŸ—‘ï¸ **Gestion de l'historique** - Supprimez les entrÃ©es individuellement
- ğŸ’¾ **Persistance** - L'historique est sauvegardÃ© dans le navigateur
- ğŸ“Š **Compteur de caractÃ¨res** - Voyez la taille de chaque section
- ğŸ¯ **Design responsive** - Fonctionne sur tous les Ã©crans

## ğŸš€ Installation

### PrÃ©requis

- Node.js 16+ installÃ© sur votre machine
- npm ou yarn

### Ã‰tapes d'installation

1. **Cloner ou crÃ©er le projet**

```bash
npx create-next-app@latest web-scraper
cd web-scraper
```

Lors de l'installation, choisissez :
- âŒ TypeScript: No
- âœ… ESLint: Yes
- âœ… Tailwind CSS: Yes
- âŒ src/ directory: No
- âŒ App Router: No (utilisez Pages Router)
- âŒ Import alias: No

2. **Installer les dÃ©pendances**

```bash
npm install axios cheerio lucide-react
```

3. **CrÃ©er la structure des fichiers**

```
web-scraper/
â”œâ”€â”€ pages/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â””â”€â”€ scrape.js      # API backend
â”‚   â””â”€â”€ index.js           # Page principale
â”œâ”€â”€ public/
â”œâ”€â”€ styles/
â”‚   â””â”€â”€ globals.css
â”œâ”€â”€ package.json
â””â”€â”€ README.md
```

4. **Copier les fichiers**

- Copiez le code fourni dans `pages/index.js`
- Copiez le code de l'API dans `pages/api/scrape.js`

5. **Lancer le projet**

```bash
npm run dev
```

6. **Ouvrir dans le navigateur**

AccÃ©dez Ã  [http://localhost:3000](http://localhost:3000)

## ğŸ“– Utilisation

### Analyser une page web

1. Entrez l'URL d'un site web dans le champ de saisie
2. Cliquez sur "Analyser" ou appuyez sur EntrÃ©e
3. Attendez quelques secondes pendant le chargement
4. Naviguez entre les onglets HTML, CSS et JavaScript

### Utiliser l'historique

1. AprÃ¨s avoir analysÃ© une URL, une icÃ´ne d'horloge ğŸ• apparaÃ®t dans le champ
2. Cliquez dessus pour ouvrir le menu dÃ©roulant
3. Cliquez sur une URL pour charger instantanÃ©ment son contenu
4. Utilisez l'icÃ´ne ğŸ—‘ï¸ pour supprimer une entrÃ©e

### Copier ou tÃ©lÃ©charger

- **Copier** : Cliquez sur le bouton "Copier" pour mettre le code dans le presse-papier
- **TÃ©lÃ©charger** : Cliquez sur "TÃ©lÃ©charger" pour sauvegarder en fichier (.html, .css, .js)

## ğŸ› ï¸ Technologies utilisÃ©es

- **[Next.js](https://nextjs.org/)** - Framework React pour applications web
- **[React](https://react.dev/)** - BibliothÃ¨que JavaScript pour interfaces utilisateur
- **[Tailwind CSS](https://tailwindcss.com/)** - Framework CSS utilitaire
- **[Axios](https://axios-http.com/)** - Client HTTP pour requÃªtes
- **[Cheerio](https://cheerio.js.org/)** - Parser HTML cÃ´tÃ© serveur
- **[Lucide React](https://lucide.dev/)** - IcÃ´nes modernes

## ğŸ“ Structure du code

### Frontend (`pages/index.js`)

- Interface utilisateur React avec hooks (useState, useEffect)
- Gestion de l'historique avec localStorage
- Nettoyage du HTML pour retirer CSS et JS inline
- SystÃ¨me de copie dans le presse-papier
- TÃ©lÃ©chargement de fichiers avec Blob API

### Backend (`pages/api/scrape.js`)

- Route API Next.js
- RÃ©cupÃ©ration du contenu avec Axios
- Parsing HTML avec Cheerio
- Extraction sÃ©parÃ©e du HTML, CSS et JavaScript
- Gestion des erreurs et timeouts

## âš™ï¸ Configuration

### Modifier le timeout

Dans `pages/api/scrape.js`, ligne 22 :

```javascript
timeout: 10000  // 10 secondes (10000ms)
```

### Modifier le nombre d'entrÃ©es dans l'historique

Dans `pages/index.js`, fonction `saveToHistory` :

```javascript
.slice(0, 10)  // Limite Ã  10 entrÃ©es
```

## ğŸ”’ Limitations

- âš ï¸ Certains sites bloquent le scraping (protection CORS, anti-bot)
- âš ï¸ Les sites avec authentification ne sont pas accessibles
- âš ï¸ Les fichiers CSS/JS externes ne sont pas tÃ©lÃ©chargÃ©s (seulement les liens)
- âš ï¸ Timeout de 10 secondes par requÃªte

## ğŸ§ª Sites de test recommandÃ©s

```
https://example.com
https://github.com
https://wikipedia.org
https://developer.mozilla.org
```

## ğŸ› RÃ©solution de problÃ¨mes

### Erreur "Method not allowed"
- VÃ©rifiez que `pages/api/scrape.js` existe bien
- RedÃ©marrez le serveur de dÃ©veloppement

### Erreur "CORS"
- Certains sites bloquent les requÃªtes externes
- Essayez avec un autre site

### L'historique ne se charge pas
- VÃ©rifiez que JavaScript est activÃ©
- VÃ©rifiez les permissions localStorage dans votre navigateur

### Timeout
- Le site est peut-Ãªtre trop lent
- Augmentez le timeout dans `scrape.js`

## ğŸ“ License

Ce projet est open source et disponible sous licence MIT.

## ğŸ‘¨â€ğŸ’» Contribution

Les contributions sont les bienvenues ! N'hÃ©sitez pas Ã  :
- Signaler des bugs
- Proposer des nouvelles fonctionnalitÃ©s
- AmÃ©liorer la documentation

## ğŸ™ CrÃ©dits

DÃ©veloppÃ© avec â¤ï¸ en utilisant Next.js et React.

---

**Note** : Respectez toujours les conditions d'utilisation des sites web et les lois sur le scraping dans votre juridiction.